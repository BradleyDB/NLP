import spacy
nlp = spacy.load('en_core_web_sm')

from spacy.matcher import Matcher

matcher = Matcher(nlp.vocab)

def show_lemmas(text):
    for token in text:
        print(f'{token.text:{15}} {token.pos_:{10}} {token.lemma:<{25}} {token.lemma_:{20}} {token.tag_}')
        
        
#solarpower SolarPower
pattern1 = [{'LOWER': 'solarpower'}]
#solar, any number of punctuarion, power
pattern2 = [{'LOWER': 'solar'},{'IS_PUNCT':True,'OP':'*'},{'LOWER':'power'}]

matcher.add('SolarPower',None,pattern1,pattern2)

doc2 = nlp(u"Solar----power is solarpower yay!") #>3 hyphens
doc3 = nlp(u"Solar-power is solarpower yay!") #<=2 hyphens

found_matches_2 = matcher(doc2)
found_matches_3 = matcher(doc3)

print(found_matches_2)
print(found_matches_3)

#multiple hyphens
for match_id, start, end in found_matches_2:
    string_id = nlp.vocab.strings[match_id]  # get string representation
    span = doc2[start:end]                    # get the matched span
    print(match_id, string_id, start, end, span.text)
    
    
#one hyphen
for match_id, start, end in found_matches_3: 
    string_id = nlp.vocab.strings[match_id]  # get string representation
    span = doc3[start:end]                    # get the matched span
    print(match_id, string_id, start, end, span.text)
    
    
show_lemmas(doc2) #many hyphens
show_lemmas(doc3) #<2 hyphens
